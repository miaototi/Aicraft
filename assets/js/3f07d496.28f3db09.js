"use strict";(globalThis.webpackChunkaicraft_website=globalThis.webpackChunkaicraft_website||[]).push([[534],{7990(e,r,a){a.r(r),a.d(r,{assets:()=>t,contentTitle:()=>i,default:()=>h,frontMatter:()=>c,metadata:()=>d,toc:()=>o});const d=JSON.parse('{"id":"api/autograd","title":"Autograd","description":"#include","source":"@site/docs/api/autograd.md","sourceDirName":"api","slug":"/api/autograd","permalink":"/Aicraft/docs/api/autograd","draft":false,"unlisted":false,"editUrl":"https://github.com/TobiasTesauri/Aicraft/tree/main/docs/api/autograd.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Autograd"},"sidebar":"docsSidebar","previous":{"title":"Tensor","permalink":"/Aicraft/docs/api/tensor"},"next":{"title":"Layers","permalink":"/Aicraft/docs/api/layers"}}');var s=a(4848),n=a(8453);const c={sidebar_position:3,title:"Autograd"},i="Autograd API",t={},o=[{value:"Core Functions",id:"core-functions",level:2},{value:"<code>ac_backward</code>",id:"ac_backward",level:3},{value:"<code>ac_zero_grad</code>",id:"ac_zero_grad",level:3},{value:"Supported Operations",id:"supported-operations",level:2},{value:"How It Works",id:"how-it-works",level:2},{value:"Forward Pass",id:"forward-pass",level:3},{value:"Backward Pass",id:"backward-pass",level:3},{value:"O(1) Visited Check",id:"o1-visited-check",level:3},{value:"Gradient Computation Examples",id:"gradient-computation-examples",level:2},{value:"ADD backward",id:"add-backward",level:3},{value:"MATMUL backward (C = A @ B)",id:"matmul-backward-c--a--b",level:3},{value:"ReLU backward",id:"relu-backward",level:3},{value:"Cross-Entropy backward",id:"cross-entropy-backward",level:3},{value:"Parameter Groups",id:"parameter-groups",level:2}];function l(e){const r={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",...(0,n.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(r.header,{children:(0,s.jsx)(r.h1,{id:"autograd-api",children:"Autograd API"})}),"\n",(0,s.jsx)(r.p,{children:(0,s.jsx)(r.code,{children:"#include <aicraft/autograd.h>"})}),"\n",(0,s.jsx)(r.p,{children:"Reverse-mode automatic differentiation engine with dynamic graph construction and 22 supported operation types."}),"\n",(0,s.jsx)(r.h2,{id:"core-functions",children:"Core Functions"}),"\n",(0,s.jsx)(r.h3,{id:"ac_backward",children:(0,s.jsx)(r.code,{children:"ac_backward"})}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-c",children:"void ac_backward(ac_tensor* loss);\n"})}),"\n",(0,s.jsxs)(r.p,{children:["Compute gradients of ",(0,s.jsx)(r.code,{children:"loss"})," with respect to all tensors with ",(0,s.jsx)(r.code,{children:"requires_grad=1"}),"."]}),"\n",(0,s.jsxs)(r.ol,{children:["\n",(0,s.jsxs)(r.li,{children:["Seeds ",(0,s.jsx)(r.code,{children:"loss->grad = 1.0"})]}),"\n",(0,s.jsx)(r.li,{children:"Topological sort via DFS"}),"\n",(0,s.jsx)(r.li,{children:"Reverse-order backward dispatch"}),"\n"]}),"\n",(0,s.jsx)(r.h3,{id:"ac_zero_grad",children:(0,s.jsx)(r.code,{children:"ac_zero_grad"})}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-c",children:"void ac_zero_grad(ac_param_group* params);\n"})}),"\n",(0,s.jsxs)(r.p,{children:["Zero all ",(0,s.jsx)(r.code,{children:".grad"})," buffers in the parameter group. ",(0,s.jsx)(r.strong,{children:"Must be called before each forward pass."})]}),"\n",(0,s.jsx)(r.h2,{id:"supported-operations",children:"Supported Operations"}),"\n",(0,s.jsx)(r.p,{children:"The backward pass handles 22 operation types:"}),"\n",(0,s.jsxs)(r.table,{children:[(0,s.jsx)(r.thead,{children:(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.th,{children:"Category"}),(0,s.jsx)(r.th,{children:"Operations"})]})}),(0,s.jsxs)(r.tbody,{children:[(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.strong,{children:"Arithmetic"})}),(0,s.jsx)(r.td,{children:"ADD, SUB, MUL, DIV, MATMUL, SCALE, BIAS_ADD"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.strong,{children:"Reductions"})}),(0,s.jsx)(r.td,{children:"SUM, MEAN"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.strong,{children:"Activations"})}),(0,s.jsx)(r.td,{children:"RELU, SIGMOID, TANH, SOFTMAX"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.strong,{children:"Losses"})}),(0,s.jsx)(r.td,{children:"MSE, Cross-Entropy, BCE"})]}),(0,s.jsxs)(r.tr,{children:[(0,s.jsx)(r.td,{children:(0,s.jsx)(r.strong,{children:"Layers"})}),(0,s.jsx)(r.td,{children:"FLATTEN, RESHAPE, DROPOUT, MAXPOOL, BATCHNORM, CONV2D"})]})]})]}),"\n",(0,s.jsx)(r.h2,{id:"how-it-works",children:"How It Works"}),"\n",(0,s.jsx)(r.h3,{id:"forward-pass",children:"Forward Pass"}),"\n",(0,s.jsx)(r.p,{children:"Each operation records autograd metadata:"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-c",children:"ac_tensor* c = ac_tensor_add(a, b);\r\n// c->op = AC_OP_ADD\r\n// c->src[0] = a\r\n// c->src[1] = b\r\n// c->requires_grad = (a->requires_grad || b->requires_grad)\n"})}),"\n",(0,s.jsx)(r.h3,{id:"backward-pass",children:"Backward Pass"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-c",children:"ac_backward(loss);\r\n// After this, all param->grad fields are populated\n"})}),"\n",(0,s.jsx)(r.h3,{id:"o1-visited-check",children:"O(1) Visited Check"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-c",children:"// Global epoch increments each backward call\r\nextern int g_autograd_epoch;\r\n\r\n// Each tensor stores last visited epoch\r\n// visited = (tensor->autograd_epoch == g_autograd_epoch)\r\n// No hash set or linear scan needed\n"})}),"\n",(0,s.jsx)(r.h2,{id:"gradient-computation-examples",children:"Gradient Computation Examples"}),"\n",(0,s.jsx)(r.h3,{id:"add-backward",children:"ADD backward"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{children:"dA += dC\r\ndB += dC\n"})}),"\n",(0,s.jsx)(r.h3,{id:"matmul-backward-c--a--b",children:"MATMUL backward (C = A @ B)"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{children:"dA += dC @ B^T\r\ndB += A^T @ dC\n"})}),"\n",(0,s.jsx)(r.h3,{id:"relu-backward",children:"ReLU backward"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{children:"dA += dC * (A > 0)   // SIMD masked move\n"})}),"\n",(0,s.jsx)(r.h3,{id:"cross-entropy-backward",children:"Cross-Entropy backward"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{children:"dLogits = softmax(logits) - labels   // Fused softmax+CE gradient\n"})}),"\n",(0,s.jsx)(r.h2,{id:"parameter-groups",children:"Parameter Groups"}),"\n",(0,s.jsx)(r.pre,{children:(0,s.jsx)(r.code,{className:"language-c",children:"ac_param_group params;\r\nac_param_group_init(&params);             // Initialize (dynamic array)\r\nac_param_group_add(&params, tensor);       // Add a parameter\r\nac_zero_grad(&params);                     // Zero all gradients\r\nac_param_group_destroy(&params);           // Free\n"})}),"\n",(0,s.jsx)(r.p,{children:"The parameter group grows dynamically \u2014 no static limit."})]})}function h(e={}){const{wrapper:r}={...(0,n.R)(),...e.components};return r?(0,s.jsx)(r,{...e,children:(0,s.jsx)(l,{...e})}):l(e)}},8453(e,r,a){a.d(r,{R:()=>c,x:()=>i});var d=a(6540);const s={},n=d.createContext(s);function c(e){const r=d.useContext(n);return d.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function i(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:c(e.components),d.createElement(n.Provider,{value:r},e.children)}}}]);