"use strict";(globalThis.webpackChunkaicraft_website=globalThis.webpackChunkaicraft_website||[]).push([[842],{6880(e,n,s){s.r(n),s.d(n,{assets:()=>c,contentTitle:()=>a,default:()=>h,frontMatter:()=>l,metadata:()=>r,toc:()=>d});const r=JSON.parse('{"id":"design-decisions","title":"Design Decisions","description":"The reasoning behind Aicraft\'s key architectural choices.","source":"@site/docs/design-decisions.md","sourceDirName":".","slug":"/design-decisions","permalink":"/docs/design-decisions","draft":false,"unlisted":false,"editUrl":"https://github.com/TobiasTesauri/Aicraft/tree/main/docs/design-decisions.md","tags":[],"version":"current","sidebarPosition":12,"frontMatter":{"sidebar_position":12,"title":"Design Decisions"},"sidebar":"docsSidebar","previous":{"title":"Benchmarks","permalink":"/docs/benchmarks"}}');var i=s(4848),t=s(8453);const l={sidebar_position:12,title:"Design Decisions"},a="Design Decisions",c={},d=[{value:"1. Header-Only Core",id:"1-header-only-core",level:2},{value:"2. Arena Allocation",id:"2-arena-allocation",level:2},{value:"3. SIMD Everywhere",id:"3-simd-everywhere",level:2},{value:"4. BLIS-style GEMM",id:"4-blis-style-gemm",level:2},{value:"5. Fused Operations",id:"5-fused-operations",level:2},{value:"6. No Abstraction Tax",id:"6-no-abstraction-tax",level:2},{value:"7. Vulkan over CUDA",id:"7-vulkan-over-cuda",level:2},{value:"8. Dynamic Autograd Graph",id:"8-dynamic-autograd-graph",level:2},{value:"9. Production Error Handling",id:"9-production-error-handling",level:2},{value:"10. xoshiro128** PRNG",id:"10-xoshiro128-prng",level:2}];function o(e){const n={code:"code",h1:"h1",h2:"h2",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,t.R)(),...e.components};return(0,i.jsxs)(i.Fragment,{children:[(0,i.jsx)(n.header,{children:(0,i.jsx)(n.h1,{id:"design-decisions",children:"Design Decisions"})}),"\n",(0,i.jsx)(n.p,{children:"The reasoning behind Aicraft's key architectural choices."}),"\n",(0,i.jsx)(n.h2,{id:"1-header-only-core",children:"1. Header-Only Core"}),"\n",(0,i.jsxs)(n.p,{children:["All hot paths are ",(0,i.jsx)(n.code,{children:"static inline"})," in header files \u2014 zero function call overhead for tensor operations, SIMD kernels, and layer forward passes."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Trade-off"}),": Longer compile times for the first build, but zero-cost abstractions at runtime. Only ",(0,i.jsx)(n.code,{children:"core.c"})," and ",(0,i.jsx)(n.code,{children:"vulkan.c"})," are separate compilation units (for global state definitions and Vulkan dynamic loading)."]}),"\n",(0,i.jsx)(n.h2,{id:"2-arena-allocation",children:"2. Arena Allocation"}),"\n",(0,i.jsx)(n.p,{children:"One large allocation (64 MB blocks), bump-pointer sub-allocation. Checkpoint/restore for training loops."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why not malloc/free?"})," In a training loop, thousands of intermediate tensors are created and destroyed per epoch. Each ",(0,i.jsx)(n.code,{children:"malloc"}),"/",(0,i.jsx)(n.code,{children:"free"})," is a syscall with overhead. The arena allocator:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Allocates in O(1) \u2014 bump a pointer"}),"\n",(0,i.jsx)(n.li,{children:"Frees all intermediates in O(1) \u2014 reset pointer position"}),"\n",(0,i.jsx)(n.li,{children:"Zero fragmentation \u2014 linear allocation pattern"}),"\n",(0,i.jsx)(n.li,{children:"SIMD-aligned by default"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"3-simd-everywhere",children:"3. SIMD Everywhere"}),"\n",(0,i.jsx)(n.p,{children:"Every numerical kernel uses hand-tuned intrinsics with cascading fallback:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{children:"AVX-512 \u2192 AVX2 \u2192 SSE4.2 \u2192 ARM NEON \u2192 Scalar\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why not auto-vectorization?"})," Compilers miss opportunities for:"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Register tiling (12-register accumulators in GEMM micro-kernels)"}),"\n",(0,i.jsx)(n.li,{children:"Prefetch hints for L1 cache"}),"\n",(0,i.jsx)(n.li,{children:"FMA instruction selection"}),"\n",(0,i.jsx)(n.li,{children:"Optimal unroll factors per architecture"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"4-blis-style-gemm",children:"4. BLIS-style GEMM"}),"\n",(0,i.jsx)(n.p,{children:"Panel packing + cache-blocked 5-loop tiling with architecture-specific micro-kernels."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why not just call OpenBLAS?"})," Zero dependencies is a project goal. The BLIS algorithm is well-documented and achieves near-peak FLOPS when micro-kernels are properly tuned. Our implementation uses the same algorithm as OpenBLAS/BLIS themselves."]}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Cache blocking parameters"}),":"]}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"Parameter"}),(0,i.jsx)(n.th,{children:"Value"}),(0,i.jsx)(n.th,{children:"Rationale"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"MC"}),(0,i.jsx)(n.td,{children:"72"}),(0,i.jsx)(n.td,{children:"~36 KB packed A panel \u2192 fits L1 (32-48 KB)"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"KC"}),(0,i.jsx)(n.td,{children:"256"}),(0,i.jsx)(n.td,{children:"~72 KB packed B slice \u2192 fits L2"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"NC"}),(0,i.jsx)(n.td,{children:"4096"}),(0,i.jsx)(n.td,{children:"Full N dimension \u2192 L3 streaming"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"MR"}),(0,i.jsx)(n.td,{children:"6"}),(0,i.jsx)(n.td,{children:"6 rows \xd7 NR columns = 12 accumulators \u2248 max FP regs"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"NR"}),(0,i.jsx)(n.td,{children:"32/16/8"}),(0,i.jsx)(n.td,{children:"AVX-512/AVX2/NEON SIMD width"})]})]})]}),"\n",(0,i.jsx)(n.h2,{id:"5-fused-operations",children:"5. Fused Operations"}),"\n",(0,i.jsx)(n.p,{children:"Combined softmax + cross-entropy eliminates an intermediate buffer and improves numerical stability:"}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-c",children:"// Instead of:\r\nsoftmax = exp(x) / sum(exp(x))  // intermediate buffer\r\nloss = -sum(y * log(softmax))    // second pass\r\n\r\n// Fused:\r\nloss = -sum(y * log_softmax(x))  // single pass, log-sum-exp trick\r\n// Gradient: softmax(x) - y       // closed-form, no log needed\n"})}),"\n",(0,i.jsx)(n.h2,{id:"6-no-abstraction-tax",children:"6. No Abstraction Tax"}),"\n",(0,i.jsx)(n.p,{children:"Direct C structs + functions. No virtual dispatch, no RTTI, no vtables."}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-c",children:"// Layer is a plain struct\r\nac_dense layer;\r\nac_dense_init(&layer, 784, 10);\r\n\r\n// Forward is a direct function call \u2014 inlined by compiler\r\nac_tensor* out = ac_dense_forward(&layer, input);\n"})}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Comparison"}),": PyTorch uses ",(0,i.jsx)(n.code,{children:"Module.forward()"})," via Python virtual dispatch \u2192 C++ virtual dispatch \u2192 kernel launch. Aicraft inlines directly to SIMD instructions."]}),"\n",(0,i.jsx)(n.h2,{id:"7-vulkan-over-cuda",children:"7. Vulkan over CUDA"}),"\n",(0,i.jsx)(n.p,{children:"Vulkan compute works across all GPU vendors (NVIDIA, AMD, Intel, Qualcomm). CUDA is NVIDIA-only."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Trade-offs"}),":"]}),"\n",(0,i.jsxs)(n.ul,{children:["\n",(0,i.jsx)(n.li,{children:"Vulkan has more boilerplate (pipeline creation, descriptor sets)"}),"\n",(0,i.jsx)(n.li,{children:"CUDA has more mature ML ecosystem (cuDNN, cuBLAS)"}),"\n",(0,i.jsx)(n.li,{children:"Vulkan enables deployment on mobile GPUs and integrated graphics"}),"\n",(0,i.jsx)(n.li,{children:"Dynamic loading means no compile-time SDK dependency"}),"\n"]}),"\n",(0,i.jsx)(n.h2,{id:"8-dynamic-autograd-graph",children:"8. Dynamic Autograd Graph"}),"\n",(0,i.jsx)(n.p,{children:"No static limits on graph size. Param groups and topology buffers grow dynamically."}),"\n",(0,i.jsxs)(n.p,{children:[(0,i.jsx)(n.strong,{children:"Why dynamic?"})," Static limits force users to predict graph size. Dynamic allocation with the arena allocator is essentially free (bump pointer), so there's no reason to limit."]}),"\n",(0,i.jsx)(n.h2,{id:"9-production-error-handling",children:"9. Production Error Handling"}),"\n",(0,i.jsxs)(n.p,{children:["Error codes + user callbacks replace raw ",(0,i.jsx)(n.code,{children:"assert()"}),"."]}),"\n",(0,i.jsx)(n.pre,{children:(0,i.jsx)(n.code,{className:"language-c",children:'// Instead of:\r\nassert(shape.ndim > 0);  // crashes in release, no recovery\r\n\r\n// We use:\r\nif (shape.ndim == 0) {\r\n    AC_RETURN_ERROR(AC_ERROR_SHAPE, "empty shape");\r\n    // User callback notified, error state set, function returns error code\r\n}\n'})}),"\n",(0,i.jsx)(n.h2,{id:"10-xoshiro128-prng",children:"10. xoshiro128** PRNG"}),"\n",(0,i.jsx)(n.p,{children:"Passes BigCrush statistical tests (unlike basic LCGs). Fast, small state (16 bytes), good quality."}),"\n",(0,i.jsxs)(n.table,{children:[(0,i.jsx)(n.thead,{children:(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.th,{children:"PRNG"}),(0,i.jsx)(n.th,{children:"BigCrush"}),(0,i.jsx)(n.th,{children:"Speed"}),(0,i.jsx)(n.th,{children:"State Size"})]})}),(0,i.jsxs)(n.tbody,{children:[(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"LCG"}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Fails"})}),(0,i.jsx)(n.td,{children:"Fast"}),(0,i.jsx)(n.td,{children:"4 bytes"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsx)(n.td,{children:"Mersenne Twister"}),(0,i.jsx)(n.td,{children:"Passes"}),(0,i.jsx)(n.td,{children:"Medium"}),(0,i.jsx)(n.td,{children:"2.5 KB"})]}),(0,i.jsxs)(n.tr,{children:[(0,i.jsxs)(n.td,{children:[(0,i.jsx)(n.strong,{children:"xoshiro128"}),"**"]}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Passes"})}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"Fast"})}),(0,i.jsx)(n.td,{children:(0,i.jsx)(n.strong,{children:"16 bytes"})})]})]})]})]})}function h(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,i.jsx)(n,{...e,children:(0,i.jsx)(o,{...e})}):o(e)}},8453(e,n,s){s.d(n,{R:()=>l,x:()=>a});var r=s(6540);const i={},t=r.createContext(i);function l(e){const n=r.useContext(t);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function a(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:l(e.components),r.createElement(t.Provider,{value:n},e.children)}}}]);