"use strict";(globalThis.webpackChunkaicraft_website=globalThis.webpackChunkaicraft_website||[]).push([[753],{9524(e,n,i){i.r(n),i.d(n,{assets:()=>t,contentTitle:()=>l,default:()=>h,frontMatter:()=>d,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"guides/vulkan","title":"Vulkan GPU","description":"Aicraft includes an optional Vulkan compute backend for GPU-accelerated tensor operations. Unlike CUDA, Vulkan works across all GPU vendors (NVIDIA, AMD, Intel, Qualcomm).","source":"@site/docs/guides/vulkan.md","sourceDirName":"guides","slug":"/guides/vulkan","permalink":"/docs/guides/vulkan","draft":false,"unlisted":false,"editUrl":"https://github.com/TobiasTesauri/Aicraft/tree/main/docs/guides/vulkan.md","tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"sidebar_position":3,"title":"Vulkan GPU"},"sidebar":"docsSidebar","previous":{"title":"Edge Deployment","permalink":"/docs/guides/edge-deployment"},"next":{"title":"Serialization","permalink":"/docs/guides/serialization"}}');var s=i(4848),a=i(8453);const d={sidebar_position:3,title:"Vulkan GPU"},l="Vulkan GPU Compute",t={},c=[{value:"Setup",id:"setup",level:2},{value:"Prerequisites",id:"prerequisites",level:3},{value:"Build with Vulkan",id:"build-with-vulkan",level:3},{value:"How It Works",id:"how-it-works",level:2},{value:"Initialization",id:"initialization",level:3},{value:"Auto-Dispatch",id:"auto-dispatch",level:3},{value:"Available GPU Operations",id:"available-gpu-operations",level:2},{value:"GEMM (Matrix Multiplication)",id:"gemm-matrix-multiplication",level:3},{value:"Element-wise Operations",id:"element-wise-operations",level:3},{value:"Activations (forward + backward)",id:"activations-forward--backward",level:3},{value:"Reductions",id:"reductions",level:3},{value:"GPU Memory Management",id:"gpu-memory-management",level:2},{value:"Shader Pipeline",id:"shader-pipeline",level:2},{value:"Performance Considerations",id:"performance-considerations",level:2}];function o(e){const n={a:"a",admonition:"admonition",code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,a.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.header,{children:(0,s.jsx)(n.h1,{id:"vulkan-gpu-compute",children:"Vulkan GPU Compute"})}),"\n",(0,s.jsx)(n.p,{children:"Aicraft includes an optional Vulkan compute backend for GPU-accelerated tensor operations. Unlike CUDA, Vulkan works across all GPU vendors (NVIDIA, AMD, Intel, Qualcomm)."}),"\n",(0,s.jsx)(n.h2,{id:"setup",children:"Setup"}),"\n",(0,s.jsx)(n.h3,{id:"prerequisites",children:"Prerequisites"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.a,{href:"https://vulkan.lunarg.com/",children:"Vulkan SDK"})," (headers + ",(0,s.jsx)(n.code,{children:"glslc"})," shader compiler)"]}),"\n",(0,s.jsx)(n.li,{children:"A Vulkan-capable GPU with up-to-date drivers"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"build-with-vulkan",children:"Build with Vulkan"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"cmake .. -DCMAKE_BUILD_TYPE=Release -DAICRAFT_ENABLE_VULKAN=ON\r\ncmake --build . --config Release\n"})}),"\n",(0,s.jsx)(n.h2,{id:"how-it-works",children:"How It Works"}),"\n",(0,s.jsx)(n.h3,{id:"initialization",children:"Initialization"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"ac_init();  // also calls ac_vk_init() if Vulkan is enabled\n"})}),"\n",(0,s.jsxs)(n.p,{children:[(0,s.jsx)(n.code,{children:"ac_vk_init()"})," creates:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"Vulkan instance and device"}),"\n",(0,s.jsx)(n.li,{children:"Command pool and command buffers"}),"\n",(0,s.jsx)(n.li,{children:"Descriptor pool for shader bindings"}),"\n",(0,s.jsx)(n.li,{children:"16 MB staging buffer for host\u2194GPU transfers"}),"\n",(0,s.jsx)(n.li,{children:"Pipeline cache for compiled shaders"}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"auto-dispatch",children:"Auto-Dispatch"}),"\n",(0,s.jsx)(n.p,{children:"Aicraft automatically decides whether to use GPU or CPU for each operation:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"// Automatic: GPU for large tensors, CPU SIMD for small ones\r\nint use_gpu = ac_vk_should_use_gpu(tensor_size);\r\n// Returns true when tensor_size >= 4096 elements\n"})}),"\n",(0,s.jsx)(n.p,{children:"This threshold can be tuned. The overhead of GPU dispatch (buffer upload, kernel launch, download) only pays off for larger tensors."}),"\n",(0,s.jsx)(n.h2,{id:"available-gpu-operations",children:"Available GPU Operations"}),"\n",(0,s.jsx)(n.h3,{id:"gemm-matrix-multiplication",children:"GEMM (Matrix Multiplication)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"ac_vk_gemm(A_gpu, B_gpu, C_gpu, M, N, K, alpha, beta);\r\n// C = alpha * A @ B + beta * C\r\n// Uses 16\xd716 shared-memory tiling\n"})}),"\n",(0,s.jsx)(n.p,{children:"The GEMM shader uses shared-memory blocking:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-glsl",children:"// gemm.comp \u2014 16\xd716 tile with shared memory\r\nshared float tileA[TILE][TILE];\r\nshared float tileB[TILE][TILE];\r\n\r\n// Load tiles \u2192 barrier \u2192 accumulate \u2192 barrier \u2192 next tile\n"})}),"\n",(0,s.jsx)(n.h3,{id:"element-wise-operations",children:"Element-wise Operations"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"ac_vk_add(X, Y, Out, n);       // Out = X + Y\r\nac_vk_mul(X, Y, Out, n);       // Out = X * Y\r\nac_vk_scale(X, Out, n, alpha); // Out = X * alpha\r\nac_vk_fma(X, Y, Out, n, a);   // Out = X * Y + a\n"})}),"\n",(0,s.jsx)(n.h3,{id:"activations-forward--backward",children:"Activations (forward + backward)"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"ac_vk_relu(X, Out, n);                 // Out = max(0, X)\r\nac_vk_relu_backward(X, Grad, Out, n);  // dX = Grad * (X > 0)\r\nac_vk_sigmoid(X, Out, n);              // Out = 1/(1+exp(-X))\r\nac_vk_sigmoid_backward(Out, Grad, DX, n);\r\nac_vk_tanh_act(X, Out, n);             // Out = tanh(X)\r\nac_vk_tanh_backward(Out, Grad, DX, n);\n"})}),"\n",(0,s.jsx)(n.h3,{id:"reductions",children:"Reductions"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"ac_vk_softmax(X, Out, n);  // Row-wise softmax\r\nac_vk_sum(X, Out, n);      // Parallel reduction sum\n"})}),"\n",(0,s.jsxs)(n.p,{children:["The sum shader uses a ",(0,s.jsx)(n.strong,{children:"two-stage parallel reduction"}),": each workgroup of 256 threads reduces a chunk using shared memory, writing partial sums. The host runs a second pass if needed."]}),"\n",(0,s.jsx)(n.h2,{id:"gpu-memory-management",children:"GPU Memory Management"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-c",children:"// Allocate GPU buffer\r\nac_vk_buffer buf;\r\nac_vk_create_buffer(&buf, size_in_bytes);\r\n\r\n// Upload data to GPU\r\nac_vk_upload(&buf, host_data, size_in_bytes);\r\n\r\n// Download results\r\nac_vk_download(&buf, host_data, size_in_bytes);\r\n\r\n// Free GPU buffer\r\nac_vk_destroy_buffer(&buf);\n"})}),"\n",(0,s.jsxs)(n.p,{children:["Transfers use a 16 MB staging buffer with ",(0,s.jsx)(n.code,{children:"vkMapMemory"})," for efficient host\u2194device copies."]}),"\n",(0,s.jsx)(n.h2,{id:"shader-pipeline",children:"Shader Pipeline"}),"\n",(0,s.jsx)(n.p,{children:"Each operation has a dedicated GLSL compute shader:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Shader"}),(0,s.jsx)(n.th,{children:"Workgroup Size"}),(0,s.jsx)(n.th,{children:"Description"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"gemm.comp"})}),(0,s.jsx)(n.td,{children:"16\xd716"}),(0,s.jsx)(n.td,{children:"Tiled GEMM with shared memory"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"add.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"Element-wise addition"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"mul.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"Element-wise multiplication"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"scale.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"Scalar multiplication"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"fma.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"Fused multiply-add"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"relu.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"ReLU forward"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"relu_backward.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"ReLU backward"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"sigmoid.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"Sigmoid forward"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"sigmoid_backward.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"Sigmoid backward"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"tanh_act.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"Tanh forward"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"tanh_backward.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"Tanh backward"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"softmax.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"Row-wise softmax"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"sum.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"Parallel reduction sum"})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"max.comp"})}),(0,s.jsx)(n.td,{children:"256"}),(0,s.jsx)(n.td,{children:"Parallel reduction max"})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:["All shaders use ",(0,s.jsx)(n.strong,{children:"push constants"})," for runtime parameters (tensor size, scalar values) \u2014 avoiding descriptor set updates for each dispatch."]}),"\n",(0,s.jsx)(n.h2,{id:"performance-considerations",children:"Performance Considerations"}),"\n",(0,s.jsx)(n.admonition,{title:"When to Use GPU",type:"tip",children:(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Use GPU"}),": Large GEMM (\u2265512\xd7512), batch inference, large element-wise ops (\u22654096 elements)"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Use CPU"}),": Small tensors, single-sample inference, operations where transfer overhead dominates"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.strong,{children:"Auto-dispatch"}),": Let ",(0,s.jsx)(n.code,{children:"ac_vk_should_use_gpu()"})," decide automatically"]}),"\n"]})}),"\n",(0,s.jsx)(n.admonition,{title:"Transfer Overhead",type:"caution",children:(0,s.jsx)(n.p,{children:"Each GPU operation requires upload \u2192 compute \u2192 download. For small tensors, this overhead exceeds the compute savings. The auto-dispatch handles this, but be aware when writing custom pipelines."})})]})}function h(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(o,{...e})}):o(e)}},8453(e,n,i){i.d(n,{R:()=>d,x:()=>l});var r=i(6540);const s={},a=r.createContext(s);function d(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:d(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);