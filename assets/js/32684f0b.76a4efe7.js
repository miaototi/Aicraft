"use strict";(globalThis.webpackChunkaicraft_website=globalThis.webpackChunkaicraft_website||[]).push([[474],{7402(e,n,a){a.r(n),a.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>u,frontMatter:()=>s,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"api/quantize","title":"Quantization","description":"#include","source":"@site/docs/api/quantize.md","sourceDirName":"api","slug":"/api/quantize","permalink":"/docs/api/quantize","draft":false,"unlisted":false,"editUrl":"https://github.com/TobiasTesauri/Aicraft/tree/main/docs/api/quantize.md","tags":[],"version":"current","sidebarPosition":9,"frontMatter":{"sidebar_position":9,"title":"Quantization"},"sidebar":"docsSidebar","previous":{"title":"SIMD Kernels","permalink":"/docs/api/simd"},"next":{"title":"Vulkan Backend","permalink":"/docs/api/vulkan"}}');var t=a(4848),r=a(8453);const s={sidebar_position:9,title:"Quantization"},c="Quantization API",d={},l=[{value:"Structures",id:"structures",level:2},{value:"<code>ac_quant_params</code>",id:"ac_quant_params",level:3},{value:"<code>ac_qtensor</code>",id:"ac_qtensor",level:3},{value:"<code>ac_qdense</code>",id:"ac_qdense",level:3},{value:"Calibration",id:"calibration",level:2},{value:"Quantize / Dequantize",id:"quantize--dequantize",level:2},{value:"Quantized GEMM",id:"quantized-gemm",level:2},{value:"Quantized Dense Layer",id:"quantized-dense-layer",level:2},{value:"Model Size Estimation",id:"model-size-estimation",level:2}];function o(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"quantization-api",children:"Quantization API"})}),"\n",(0,t.jsx)(n.p,{children:(0,t.jsx)(n.code,{children:"#include <aicraft/quantize.h>"})}),"\n",(0,t.jsx)(n.p,{children:"INT8 asymmetric per-tensor affine quantization for ~4\xd7 model compression and faster inference on edge devices."}),"\n",(0,t.jsx)(n.h2,{id:"structures",children:"Structures"}),"\n",(0,t.jsx)(n.h3,{id:"ac_quant_params",children:(0,t.jsx)(n.code,{children:"ac_quant_params"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c",children:"typedef struct {\r\n    float scale;        // (max - min) / 255\r\n    int zero_point;     // round(-min / scale)\r\n    float min, max;     // Calibrated range\r\n} ac_quant_params;\n"})}),"\n",(0,t.jsx)(n.h3,{id:"ac_qtensor",children:(0,t.jsx)(n.code,{children:"ac_qtensor"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c",children:"typedef struct {\r\n    uint8_t* data;      // Quantized values\r\n    ac_shape shape;\r\n    ac_quant_params qp;\r\n} ac_qtensor;\n"})}),"\n",(0,t.jsx)(n.h3,{id:"ac_qdense",children:(0,t.jsx)(n.code,{children:"ac_qdense"})}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c",children:"typedef struct {\r\n    ac_qtensor qweight;    // Quantized weight matrix\r\n    float* bias;           // Bias remains in FP32\r\n    ac_size in_features, out_features;\r\n} ac_qdense;\n"})}),"\n",(0,t.jsx)(n.h2,{id:"calibration",children:"Calibration"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c",children:"ac_quant_params qp;\r\nac_calibrate(float_data, num_elements, &qp);\r\n// Scans for min/max, ensures zero is representable\n"})}),"\n",(0,t.jsx)(n.h2,{id:"quantize--dequantize",children:"Quantize / Dequantize"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c",children:"// Float32 \u2192 UINT8\r\nac_qtensor qt;\r\nac_quantize(float_tensor, &qt);\r\n\r\n// UINT8 \u2192 Float32\r\nac_tensor* recovered = ac_dequantize(&qt);\n"})}),"\n",(0,t.jsx)(n.p,{children:"SIMD-accelerated:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"AVX2"}),": 8-wide ",(0,t.jsx)(n.code,{children:"_mm256_cvtps_epi32"})," \u2192 ",(0,t.jsx)(n.code,{children:"_mm_packs_epi32"})," \u2192 ",(0,t.jsx)(n.code,{children:"_mm_packus_epi16"})]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"NEON"}),": 4-wide ",(0,t.jsx)(n.code,{children:"vcvtnq_s32_f32"})," \u2192 ",(0,t.jsx)(n.code,{children:"vmovn"})," narrowing"]}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"quantized-gemm",children:"Quantized GEMM"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c",children:"void ac_qgemm(const ac_qtensor* A, const ac_qtensor* B,\r\n              float* C, ac_size M, ac_size N, ac_size K);\n"})}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsxs)(n.li,{children:["INT8 multiplication with ",(0,t.jsx)(n.strong,{children:"INT32 accumulation"})," (prevents overflow)"]}),"\n",(0,t.jsxs)(n.li,{children:["NEON: widening multiply-accumulate (",(0,t.jsx)(n.code,{children:"vmull_u8"})," + ",(0,t.jsx)(n.code,{children:"vaddw"}),")"]}),"\n",(0,t.jsx)(n.li,{children:"Output is dequantized to FP32"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"quantized-dense-layer",children:"Quantized Dense Layer"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c",children:"// Create from trained FP32 layer\r\nac_qdense qlayer;\r\nac_qdense_from_dense(&qlayer, dense.weight, dense.bias,\r\n                     in_features, out_features);\r\n\r\n// Run quantized inference\r\nac_tensor* output = ac_qdense_forward(&qlayer, float_input);\r\n// Input is quantized on-the-fly \u2192 QGEMM \u2192 dequantize \u2192 add bias \u2192 float output\n"})}),"\n",(0,t.jsx)(n.h2,{id:"model-size-estimation",children:"Model Size Estimation"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-c",children:"ac_model_size_info info = ac_estimate_model_size(&params);\r\nac_print_model_size(&info);\n"})}),"\n",(0,t.jsx)(n.p,{children:"Output:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"FP32 model size:   804.00 KB (206,346 params)\r\nINT8 model size:   201.00 KB\r\nCompression ratio: 4.00\xd7\n"})})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(o,{...e})}):o(e)}},8453(e,n,a){a.d(n,{R:()=>s,x:()=>c});var i=a(6540);const t={},r=i.createContext(t);function s(e){const n=i.useContext(r);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function c(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:s(e.components),i.createElement(r.Provider,{value:n},e.children)}}}]);